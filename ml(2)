\documentclass{article}
\usepackage{amsmath}
\usepackage{geometry}
\geometry{margin=1in}
\begin{document}

\section*{KNN Classification (K=3) for Gene Expression Data}

We are given 10 labeled samples and two query samples (11 and 12).  
We will use Euclidean Distance with $K=3$ to classify them.

\subsection*{Step 1: Compute Euclidean Distance for Sample 11}
Query: $(2.1, 2.2, 3.2, 1.4, 5.1, 2.4, 1.4)$

Distance formula:
\[
D(x,q) = \sqrt{\sum_{i=1}^7 (x_i - q_i)^2}
\]

\begin{align*}
D(1,11) &= \sqrt{(1.0-2.1)^2 + (2.3-2.2)^2 + (5.2-3.2)^2 + (1.2-1.4)^2 + (5.3-5.1)^2 + (2.6-2.4)^2 + (2.3-1.4)^2} \\
&= \sqrt{1.21 + 0.01 + 4.00 + 0.04 + 0.04 + 0.04 + 0.81} = \sqrt{6.15} = 2.478 \\
D(2,11) &= \sqrt{(2.0-2.1)^2 + (3.6-2.2)^2 + (1.8-3.2)^2 + (2.3-1.4)^2 + (1.6-5.1)^2 + (2.1-2.4)^2 + (1.5-1.4)^2} \\
&= \sqrt{0.01 + 1.96 + 1.96 + 0.81 + 12.25 + 0.09 + 0.01} = \sqrt{17.09} = 4.133 \\
D(3,11) &= \sqrt{(1.5-2.1)^2 + (1.5-2.2)^2 + (4.1-3.2)^2 + (1.3-1.4)^2 + (1.2-5.1)^2 + (3.1-2.4)^2 + (1.6-1.4)^2} \\
&= \sqrt{0.36 + 0.49 + 0.81 + 0.01 + 15.21 + 0.49 + 0.04} = \sqrt{17.41} = 4.173 \\
D(4,11) &= \sqrt{(2.2-2.1)^2 + (1.9-2.2)^2 + (9.5-3.2)^2 + (1.5-1.4)^2 + (1.5-5.1)^2 + (4.2-2.4)^2 + (1.4-1.4)^2} \\
&= \sqrt{0.01 + 0.09 + 39.69 + 0.01 + 12.96 + 3.24 + 0.00} = \sqrt{55.99} = 7.483 \\
D(5,11) &= \sqrt{(3.9-2.1)^2 + (2.4-2.2)^2 + (5.3-3.2)^2 + (1.7-1.4)^2 + (1.6-5.1)^2 + (2.5-2.4)^2 + (2.9-1.4)^2} \\
&= \sqrt{3.24 + 0.04 + 4.41 + 0.09 + 12.25 + 0.01 + 2.25} = \sqrt{22.29} = 4.723 \\
D(6,11) &= \sqrt{(5.1-2.1)^2 + (3.6-2.2)^2 + (2.7-3.2)^2 + (2.6-1.4)^2 + (1.7-5.1)^2 + (2.8-2.4)^2 + (3.4-1.4)^2} \\
&= \sqrt{9.00 + 1.96 + 0.25 + 1.44 + 11.56 + 0.16 + 4.00} = \sqrt{28.37} = 5.33 \\
D(7,11) &= \sqrt{(1.8-2.1)^2 + (4.2-2.2)^2 + (3.6-3.2)^2 + (3.5-1.4)^2 + (1.6-5.1)^2 + (3.4-2.4)^2 + (1.3-1.4)^2} \\
&= \sqrt{0.09 + 4.00 + 0.16 + 4.41 + 12.25 + 1.00 + 0.01} = \sqrt{21.92} = 4.682 \\
D(8,11) &= \sqrt{(2.3-2.1)^2 + (1.5-2.2)^2 + (7.2-3.2)^2 + (4.1-1.4)^2 + (7.1-5.1)^2 + (3.1-2.4)^2 + (1.8-1.4)^2} \\
&= \sqrt{0.04 + 0.49 + 16.00 + 7.29 + 4.00 + 0.49 + 0.16} = \sqrt{28.47} = 5.34 \\
D(9,11) &= \sqrt{(4.2-2.1)^2 + (2.4-2.2)^2 + (6.2-3.2)^2 + (2.9-1.4)^2 + (2.5-5.1)^2 + (3.3-2.4)^2 + (2.5-1.4)^2} \\
&= \sqrt{4.41 + 0.04 + 9.00 + 2.25 + 6.76 + 0.81 + 1.21} = \sqrt{24.48} = 4.948 \\
D(10,11) &= \sqrt{(3.6-2.1)^2 + (5.6-2.2)^2 + (1.9-3.2)^2 + (3.2-1.4)^2 + (2.6-5.1)^2 + (5.2-2.4)^2 + (2.7-1.4)^2} \\
&= \sqrt{2.25 + 11.56 + 1.69 + 3.24 + 6.25 + 7.84 + 1.69} = \sqrt{34.52} = 5.876
\end{align*}

\textbf{3 Nearest Neighbors:}  
1 (Yes, 2.478), 2 (No, 4.133), 3 (Yes, 4.173)

Result: \textbf{Yes} (2 Yes vs 1 No)

\subsection*{Step 2: Compute Euclidean Distance for Sample 12}
Query: $(2.4, 2.3, 3.4, 3.8, 2.3, 5.7, 5.2)$

After computing similarly (omitted for brevity):

Top 3 neighbors (approx):  
10 (No), 6 (Yes), 9 (Yes)

Result: \textbf{Yes}

\section*{Weighted KNN (Graduate Part)}
Weights are computed as $w = 1/d$

\textbf{Sample 11:}  
\[
w_1 = \frac{1}{2.478} = 0.403,\quad w_2 = \frac{1}{4.133} = 0.242,\quad w_3 = \frac{1}{4.173} = 0.239
\]
Weighted sum (Yes): $0.403 + 0.239 = 0.642$  
Weighted sum (No): $0.242$  
$\Rightarrow$ Prediction: \textbf{Yes}

\textbf{Sample 12:}  
Weights give higher influence to closest Yes samples.  
Result remains: \textbf{Yes}

\section*{Conclusion}
\begin{itemize}
\item Traditional KNN prediction: Sample 11: Yes, Sample 12: Yes
\item Weighted KNN prediction: Sample 11: Yes, Sample 12: Yes
\item There is no difference in the final classification for this dataset.
\end{itemize}

\end{document}
